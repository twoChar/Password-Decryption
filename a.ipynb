{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3726a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce470ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/twochar/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "234377"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell A — Install and import NLTK resources (run once)\n",
    "import nltk\n",
    "nltk.download(\"words\")\n",
    "\n",
    "from nltk.corpus import words as nltk_words\n",
    "\n",
    "# Build vocab set for fast lookup\n",
    "ENGLISH_VOCAB = set(w.lower() for w in nltk_words.words())\n",
    "len(ENGLISH_VOCAB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa1d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Tokenizer + optional leet normalization helper\n",
    "\n",
    "LEET_MAP = str.maketrans({\n",
    "    '0': 'o', '1': 'l', '3': 'e', '4': 'a', '5': 's', '7': 't', '@': 'a', '$': 's', '!': 'i'\n",
    "})\n",
    "\n",
    "def leet_normalize(s: str) -> str:\n",
    "    \"\"\"Return a leet-normalized version of s (lowercased).\"\"\"\n",
    "    return s.translate(LEET_MAP).lower()\n",
    "\n",
    "def tokenize(password: str, do_leet=False, use_vocab=True) -> Tuple[List[str], str]:\n",
    "    \"\"\"\n",
    "    Split password into runs: letters, digits, symbols.\n",
    "    - If use_vocab=True, only count alphabetic tokens that are in the NLTK vocab (len>=3).\n",
    "    - Otherwise they go into FRAG bucket.\n",
    "    \"\"\"\n",
    "    pw = password.strip()\n",
    "    runs = re.findall(r'[A-Za-z]+|\\d+|[^A-Za-z\\d]+', pw)\n",
    "\n",
    "    slots = []\n",
    "    for r in runs:\n",
    "        if r.isdigit():\n",
    "            slots.append((\"DIGITS\", r))\n",
    "        elif r.isalpha():\n",
    "            token = r.lower()\n",
    "            if use_vocab and len(token) >= 3 and token in ENGLISH_VOCAB:\n",
    "                slots.append((\"WORD\", token))\n",
    "            else:\n",
    "                slots.append((\"FRAG\", token))\n",
    "        else:\n",
    "            slots.append((\"SYMBOL\", r))\n",
    "\n",
    "    template = \"|\".join(f\"{t}{len(tok) if t not in ['SYMBOL','FRAG'] else t}\" \n",
    "                        for t, tok in slots)\n",
    "    return [tok for _, tok in slots], template\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c779fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — PCFGLite class\n",
    "class PCFGLite:\n",
    "    def __init__(self, alpha: float = 1.0, do_leet: bool = False):\n",
    "        self.template_counts = Counter()\n",
    "        self.slot_counts = defaultdict(Counter)  # slot_type -> Counter(token)\n",
    "        self.total_templates = 0\n",
    "        self.alpha = float(alpha)\n",
    "        self.do_leet = do_leet\n",
    "\n",
    "    def fit_list(self, pw_list: List[str], max_samples: int = None, verbose: bool = True):\n",
    "        \"\"\"\n",
    "        Fit from a list of plaintext passwords.\n",
    "        Use max_samples to limit for quick tests.\n",
    "        \"\"\"\n",
    "        for i, pw in enumerate(pw_list):\n",
    "            if max_samples and i >= max_samples:\n",
    "                break\n",
    "            if not pw:\n",
    "                continue\n",
    "            tokens, template = tokenize(pw, do_leet=self.do_leet)\n",
    "            self.template_counts[template] += 1\n",
    "            self.total_templates += 1\n",
    "            # map tokens to type and update counters\n",
    "            runs = re.findall(r'[A-Za-z]+|\\d+|[^A-Za-z\\d]+', pw)\n",
    "            for r in runs:\n",
    "                if r.isdigit():\n",
    "                    self.slot_counts[\"DIGITS\"][r] += 1\n",
    "                elif r.isalpha():\n",
    "                    token = r.lower()\n",
    "                    if self.do_leet:\n",
    "                        token = leet_normalize(token)\n",
    "\n",
    "                    if len(token) >= 3 and token in ENGLISH_VOCAB:\n",
    "                        self.slot_counts[\"WORD\"][token] += 1\n",
    "                    else:\n",
    "                        self.slot_counts[\"FRAG\"][token] += 1\n",
    "\n",
    "                else:\n",
    "                    self.slot_counts[\"SYMBOL\"][r] += 1\n",
    "        if verbose:\n",
    "            display(Markdown(f\"**Trained on {self.total_templates} templates. Unique templates: {len(self.template_counts)}**\"))\n",
    "\n",
    "    def fit_file(self, filepath: str, max_lines: int = None):\n",
    "        p = Path(filepath)\n",
    "        if not p.exists():\n",
    "            raise FileNotFoundError(filepath)\n",
    "        with p.open(\"r\", encoding=\"latin-1\", errors=\"ignore\") as f:\n",
    "            lines = (line.rstrip(\"\\n\\r\") for line in f)\n",
    "            self.fit_list(list(lines), max_samples=max_lines)\n",
    "\n",
    "    def template_prob(self, template: str) -> float:\n",
    "        V = len(self.template_counts)\n",
    "        return (self.template_counts[template] + self.alpha) / (self.total_templates + self.alpha * (V + 1))\n",
    "\n",
    "    def slot_token_prob(self, slot_type: str, token: str) -> float:\n",
    "        counter = self.slot_counts.get(slot_type, Counter())\n",
    "        total = sum(counter.values())\n",
    "        V = len(counter)\n",
    "        return (counter[token] + self.alpha) / (total + self.alpha * (V + 1))\n",
    "\n",
    "    def score(self, password: str) -> float:\n",
    "        \"\"\"Return natural-log probability score (higher = more likely under model).\"\"\"\n",
    "        tokens, template = tokenize(password, do_leet=self.do_leet)\n",
    "        # If the template was never seen, template_prob still returns smoothed value\n",
    "        logp = math.log(self.template_prob(template))\n",
    "        runs = re.findall(r'[A-Za-z]+|\\d+|[^A-Za-z\\d]+', password)\n",
    "        for r in runs:\n",
    "            if r.isdigit():\n",
    "                p = self.slot_token_prob(\"DIGITS\", r)\n",
    "            elif r.isalpha():\n",
    "                p = self.slot_token_prob(\"WORD\", r.lower())\n",
    "            else:\n",
    "                p = self.slot_token_prob(\"SYMBOL\", r)\n",
    "            logp += math.log(p)\n",
    "        return logp\n",
    "\n",
    "    def top_templates(self, n=30):\n",
    "        return self.template_counts.most_common(n)\n",
    "\n",
    "    def top_tokens(self, slot_type: str, n=30):\n",
    "        return self.slot_counts.get(slot_type, Counter()).most_common(n)\n",
    "\n",
    "    def snapshot(self, top_templates_n=200, top_words_n=500, top_digits_n=200):\n",
    "        out = {\n",
    "            \"total_templates\": self.total_templates,\n",
    "            \"unique_templates\": len(self.template_counts),\n",
    "            \"top_templates\": self.top_templates(top_templates_n),\n",
    "            \"top_words\": self.top_tokens(\"WORD\", top_words_n),\n",
    "            \"top_digits\": self.top_tokens(\"DIGITS\", top_digits_n),\n",
    "        }\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a8ff865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from file: Data-Breach/rockyou.txt\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Trained on 999999 templates. Unique templates: 1546**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Top templates"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRAGFRAG                  401146\n",
      "FRAGFRAG|DIGITS2          87727\n",
      "DIGITS6                   75055\n",
      "FRAGFRAG|DIGITS1          74558\n",
      "DIGITS8                   30286\n",
      "WORD5|DIGITS2             28224\n",
      "WORD6|DIGITS2             26894\n",
      "WORD4|DIGITS2             23459\n",
      "FRAGFRAG|DIGITS3          19225\n",
      "FRAGFRAG|DIGITS4          18222\n",
      "WORD7|DIGITS2             12067\n",
      "WORD6|DIGITS1             10005\n",
      "WORD5|DIGITS1             9819\n",
      "WORD4|DIGITS4             8589\n",
      "WORD6                     8382\n",
      "WORD5|DIGITS3             7588\n",
      "DIGITS7                   7216\n",
      "WORD7|DIGITS1             7122\n",
      "DIGITS5                   6869\n",
      "WORD4|DIGITS3             6390\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Top WORD tokens"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love                 2255\n",
      "life                 1700\n",
      "ever                 1588\n",
      "may                  1369\n",
      "eva                  1072\n",
      "june                 961\n",
      "july                 828\n",
      "sexy                 776\n",
      "angel                770\n",
      "baby                 720\n",
      "pink                 632\n",
      "chris                593\n",
      "jan                  565\n",
      "march                498\n",
      "princess             472\n",
      "star                 459\n",
      "mike                 443\n",
      "blue                 442\n",
      "password             439\n",
      "red                  438\n",
      "jesus                417\n",
      "monkey               404\n",
      "alex                 394\n",
      "john                 390\n",
      "james                387\n",
      "david                374\n",
      "marie                367\n",
      "april                365\n",
      "soccer               361\n",
      "you                  349\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Top DIGIT runs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1          65145\n",
      "2          17549\n",
      "123        16364\n",
      "4          13750\n",
      "3          12296\n",
      "12         10968\n",
      "13         8214\n",
      "7          8147\n",
      "5          7106\n",
      "11         6873\n",
      "22         5948\n",
      "23         5926\n",
      "01         5764\n",
      "21         5693\n",
      "07         5586\n",
      "14         5449\n",
      "8          5413\n",
      "10         5318\n",
      "06         4947\n",
      "69         4821\n",
      "08         4779\n",
      "15         4769\n",
      "6          4743\n",
      "16         4479\n",
      "0          4291\n",
      "9          4280\n",
      "18         4159\n",
      "17         3967\n",
      "05         3946\n",
      "24         3893\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Demo run: use a small synthetic sample if you don't want to load rockyou now.\n",
    "# Configure DATA_PATH = \"/path/to/rockyou.txt\" to load real data. For demonstration we'll use a small list.\n",
    "\n",
    "DATA_PATH = \"Data-Breach/rockyou.txt\"  # <-- set to path string if you have the file accessible\n",
    "\n",
    "# Small synthetic sample (for quick demo)\n",
    "sample_pw = [\n",
    "    \"password\", \"123456\", \"qwerty\", \"letmein\", \"password1\", \"admin123\", \"iloveyou\", \"abc123\",\n",
    "    \"sunshine\", \"passw0rd\", \"P@ssw0rd\", \"john1987\", \"alice2020!\", \"dragon\", \"welcome1\", \"football\"\n",
    "]\n",
    "\n",
    "model = PCFGLite(alpha=1.0, do_leet=True)\n",
    "\n",
    "if DATA_PATH:\n",
    "    print(\"Loading from file:\", DATA_PATH)\n",
    "    model.fit_file(DATA_PATH, max_lines=1000000)  # change max_lines or remove it for full file\n",
    "else:\n",
    "    print(\"No DATA_PATH provided — running demo on synthetic sample.\")\n",
    "    model.fit_list(sample_pw, max_samples=None)\n",
    "\n",
    "# show top templates and top tokens\n",
    "display(Markdown(\"### Top templates\"))\n",
    "for t, c in model.top_templates(20):\n",
    "    print(f\"{t:25} {c}\")\n",
    "\n",
    "display(Markdown(\"### Top WORD tokens\"))\n",
    "for w, c in model.top_tokens(\"WORD\", 30):\n",
    "    print(f\"{w:20} {c}\")\n",
    "\n",
    "display(Markdown(\"### Top DIGIT runs\"))\n",
    "for d, c in model.top_tokens(\"DIGITS\", 30):\n",
    "    print(f\"{d:10} {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f424a70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Example scores (higher = more likely under model)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "password         score = -11.8559\n",
      "P@ssw0rd         score = -56.3306\n",
      "john1987         score = -18.2752\n",
      "unique!X9        score = -41.4447\n",
      "iloveyou         score = -13.4324\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — Scoring examples & usage\n",
    "examples = [\"password\", \"P@ssw0rd\", \"john1987\", \"unique!X9\", \"iloveyou\"]\n",
    "display(Markdown(\"### Example scores (higher = more likely under model)\"))\n",
    "for ex in examples:\n",
    "    print(f\"{ex:15}  score = {model.score(ex):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8114bf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Snapshot saved to **/Users/twochar/vS/Password-Decryption/pcfg_snapshot_notebook.json** — contains top templates and top tokens."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 6 — Save snapshot for inspection (JSON)\n",
    "snap = model.snapshot()\n",
    "out_path = Path(\"pcfg_snapshot_notebook.json\")\n",
    "out_path.write_text(json.dumps(snap))\n",
    "display(Markdown(f\"Snapshot saved to **{out_path.resolve()}** — contains top templates and top tokens.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d1a5a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Top Real Words (NLTK vocab)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love                 2255\n",
      "life                 1700\n",
      "ever                 1588\n",
      "may                  1369\n",
      "eva                  1072\n",
      "june                 961\n",
      "july                 828\n",
      "sexy                 776\n",
      "angel                770\n",
      "baby                 720\n",
      "pink                 632\n",
      "chris                593\n",
      "jan                  565\n",
      "march                498\n",
      "princess             472\n",
      "star                 459\n",
      "mike                 443\n",
      "blue                 442\n",
      "password             439\n",
      "red                  438\n",
      "jesus                417\n",
      "monkey               404\n",
      "alex                 394\n",
      "john                 390\n",
      "james                387\n",
      "david                374\n",
      "marie                367\n",
      "april                365\n",
      "soccer               361\n",
      "you                  349\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Top Fragments (non-dictionary)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me                   1213\n",
      "a                    1139\n",
      "u                    1125\n",
      "m                    1091\n",
      "r                    999\n",
      "k                    947\n",
      "s                    945\n",
      "l                    924\n",
      "n                    912\n",
      "d                    813\n",
      "j                    808\n",
      "c                    797\n",
      "i                    761\n",
      "t                    751\n",
      "e                    675\n",
      "b                    661\n",
      "p                    624\n",
      "feb                  551\n",
      "x                    523\n",
      "g                    474\n",
      "dec                  464\n",
      "h                    463\n",
      "nov                  430\n",
      "w                    429\n",
      "my                   412\n",
      "y                    409\n",
      "o                    386\n",
      "f                    360\n",
      "oct                  355\n",
      "v                    347\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"### Top Real Words (NLTK vocab)\"))\n",
    "for w, c in model.top_tokens(\"WORD\", 30):\n",
    "    print(f\"{w:20} {c}\")\n",
    "\n",
    "display(Markdown(\"### Top Fragments (non-dictionary)\"))\n",
    "for f, c in model.top_tokens(\"FRAG\", 30):\n",
    "    print(f\"{f:20} {c}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
